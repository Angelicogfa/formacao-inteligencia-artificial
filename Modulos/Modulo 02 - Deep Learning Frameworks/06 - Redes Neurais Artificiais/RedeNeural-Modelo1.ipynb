{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('IA': conda)"
  },
  "interpreter": {
   "hash": "cd33b1ad81c559069350aab209dba1ac81a1a78823a0538f4b422d164d6af523"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Redes Neurais Artificiais - Multilayer Perceptron\n",
    "\n",
    "O Multilayer Perceptron (MLP) é uma arquitetura complexa e eficiente. É substancialmente formada a partir de múltiplas camadas de perceptrons e, portanto, pela presença de pelo menos uma camada oculta. Uma rede deste tipo é normalmente treinada usando aprendizagem supervisionada. \n",
    "\n",
    "Em particular, um algoritmo de aprendizagem típico para redes MLP é o chamado algoritmo de retropropagação (backpropagation).\n",
    "\n",
    "O algoritmo de retropropagação é um algoritmo de aprendizagem para redes neurais. Ele compara o valor de saída do sistema com o valor real. \n",
    "\n",
    "Com base na diferença calculada (o erro), o algoritmo modifica os pesos da rede neural, convergindo progressivamente o conjunto de valores de saída para os valores próximos dos reais. \n",
    "\n",
    "É importante notar que em redes MLP, embora você não saiba as saídas desejadas dos neurônios das camadas ocultas da rede, é sempre possível aplicar um método de aprendizagem supervisionado com base na minimização de uma função de erro através da aplicação de técnicas de gradient-descent. \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando dados sintéticos\n",
    "\n",
    "# Hiperparâmetros\n",
    "size = 200000\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando dados para x\n",
    "# https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.random.randint.html\n",
    "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.dstack.html\n",
    "x1 = np.random.randint(0, 100, size)\n",
    "x2 = np.random.randint(0, 100, size)\n",
    "x_treino = np.dstack((x1, x2))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nValores e shape de x:\n[[63 41]\n [86 47]\n [15 78]\n ...\n [49 95]\n [29 87]\n [61 52]]\n(200000, 2)\n\nValores e shape de y:\n[ 3385.8117618   4445.82085549 12179.61895004 ... 18071.\n 15154.15549442  5431.43074903]\n(200000,)\n"
     ]
    }
   ],
   "source": [
    "# Gerando dados para y\n",
    "y_treino = 3*(x1**(1/2)) + 2*(x2**2)\n",
    "\n",
    "# Print\n",
    "print(\"\\nValores e shape de x:\")\n",
    "print(x_treino)\n",
    "print(x_treino.shape)\n",
    "print(\"\\nValores e shape de y:\")\n",
    "print(y_treino)\n",
    "print(y_treino.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método 1 para construir modelos MPL com TF2\n",
    "\n",
    "# tf.keras.Sequential + fit\n",
    "\n",
    "# Define a sequência de camadas\n",
    "modelo_v1 = tf.keras.Sequential()\n",
    "\n",
    "# Camada 1 - camada de entrada\n",
    "modelo_v1.add(tf.keras.layers.Dense(64, input_shape = (2,) , activation = 'sigmoid'))\n",
    "\n",
    "# Camada 2 - camada intermediária\n",
    "modelo_v1.add(tf.keras.layers.Dense(128, activation = 'relu'))\n",
    "\n",
    "# Camada 3 - camada de saída\n",
    "modelo_v1.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "# Otimização do modelo com \n",
    "modelo_v1.compile(optimizer = tf.keras.optimizers.Adam(learning_rate), loss = tf.keras.losses.MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Treinamento do modelo:\n",
      "Epoch 1/10\n",
      "6250/6250 [==============================] - 4s 625us/step - loss: 10833236.0000\n",
      "Epoch 2/10\n",
      "6250/6250 [==============================] - 3s 497us/step - loss: 23156.3613\n",
      "Epoch 3/10\n",
      "6250/6250 [==============================] - 4s 564us/step - loss: 5741.2012\n",
      "Epoch 4/10\n",
      "6250/6250 [==============================] - 4s 668us/step - loss: 3540.8987\n",
      "Epoch 5/10\n",
      "6250/6250 [==============================] - 4s 658us/step - loss: 2798.2017\n",
      "Epoch 6/10\n",
      "6250/6250 [==============================] - 4s 595us/step - loss: 3067.8569\n",
      "Epoch 7/10\n",
      "6250/6250 [==============================] - 3s 543us/step - loss: 2134.1108\n",
      "Epoch 8/10\n",
      "6250/6250 [==============================] - 3s 491us/step - loss: 2177.2078\n",
      "Epoch 9/10\n",
      "6250/6250 [==============================] - 3s 492us/step - loss: 2135.4429\n",
      "Epoch 10/10\n",
      "6250/6250 [==============================] - 3s 504us/step - loss: 2684.9167\n",
      "\n",
      "Sumário do modelo:\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                192       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 8,641\n",
      "Trainable params: 8,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Erro Final em Treino: 470\n"
     ]
    }
   ],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam\n",
    "\n",
    "# Treinamento do modelo\n",
    "print(\"\\nTreinamento do modelo:\")\n",
    "modelo_v1.fit(x = x_treino, y = y_treino, epochs = num_epochs)\n",
    "\n",
    "# Sumário do modelo\n",
    "print(\"\\nSumário do modelo:\")\n",
    "modelo_v1.summary()\n",
    "\n",
    "# Avaliando a performance em treino\n",
    "scores_treino = modelo_v1.evaluate(x_treino, y_treino, verbose = 0)\n",
    "print(\"\\nErro Final em Treino: {:.0f}\".format(scores_treino))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nTestando o Modelo...\n\nErro Final em Teste: 33\n\n\nEntrada(x): (100, 65), Saida(y): (8480), Previsão do Modelo(y_pred): (8487)\nEntrada(x): (9, 39), Saida(y): (3051), Previsão do Modelo(y_pred): (3055)\nEntrada(x): (62, 40), Saida(y): (3224), Previsão do Modelo(y_pred): (3217)\nEntrada(x): (79, 44), Saida(y): (3899), Previsão do Modelo(y_pred): (3890)\nEntrada(x): (94, 77), Saida(y): (11887), Previsão do Modelo(y_pred): (11887)\n\n\n"
     ]
    }
   ],
   "source": [
    "# Testando o modelo\n",
    "\n",
    "# Gerando novos dados para x\n",
    "x1 = np.array([100, 9, 62, 79, 94, 91, 71, 41])\n",
    "x2 = np.array([65, 39, 40, 44, 77, 42, 36, 74])\n",
    "x_teste = np.dstack((x1, x2))[0]\n",
    "\n",
    "# Gerando novos dados para y\n",
    "y_teste = 3*(x1**(1/2)) + 2*(x2**2)\n",
    "\n",
    "# Fazendo previsões\n",
    "print(\"\\nTestando o Modelo...\")\n",
    "y_pred = modelo_v1.predict(x_teste)\n",
    "\n",
    "# Avaliando a performance em teste\n",
    "scores_teste = modelo_v1.evaluate(x_teste, y_teste, verbose = 0)\n",
    "print(\"\\nErro Final em Teste: {:.0f}\".format(scores_teste))\n",
    "\n",
    "print(\"\\n\")\n",
    "for i in range(5):\n",
    "\tprint ('''Entrada(x): ({}, {}), Saida(y): ({:.0f}), Previsão do Modelo(y_pred): ({:.0f})'''.format(x1[i], x2[i], y_teste[i], y_pred[i][0]))\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}